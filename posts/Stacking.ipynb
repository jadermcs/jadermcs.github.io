{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "layout: post\n",
    "title: Stacked Generalization\n",
    "lang: pt\n",
    "date: 2019-04-22 12:59:07\n",
    "tags: [ensemble, meta-learning]\n",
    "author: Jader Martins\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Introduced by Wolpert in 1992 [^ 1], this generalization technique consists of combining nonlinear estimators to correct their biases to a given training set, adding their capabilities for better prediction[^2].\n",
    "\n",
    "<img src=\"/images/stacking.png\" width=600px>\n",
    "\n",
    "In a [previous post](/posts/Linear-Ensemble.html) I presented the linear combination of estimators, in it we adjusted $N$ models to a $D$ dataset and a priori we defined $W$ weights for them by combining into one summation:\n",
    "\n",
    "$$\\sum_{i=1}^{N} w_{i}M_{i}$$\n",
    "\n",
    "$$\\text{given a priori} \\ W = (w_1,w_2,...w_N) \\ \\text{and} \\sum W = 1$$\n",
    "\n",
    "With this the weighted average of the predictions in general will be less biased for certain regions and may generalize more, but this method has two limitations, the weights cannot be changed after verifying the performance (if we would not be acting as a meta-estimator in test data) and is an extremely simple combination, not leveraging the strengths of the $ M $ estimators for certain regions.\n",
    "\n",
    "Wolpert then proposes an alternative to this, what if we make $ W $ pesos a learning problem? or rather, not only learn how to combine our predictions but also combine them nonlinearly using a meta estimator?\n",
    "\n",
    "Meta estimators are those who use base models to combine them or select them to improve on a performance metric, for example you reader when deciding between using a random forest or a logistic regression to predict your model you are being a meta estimator. But here the problem of generalization arises, if you continue to improve your regression or rforest you may end up overfitting the data and not being able to generalize, here then it is necessary to apply cross validation techniques to select the model, the same will happen for the stacking.\n",
    "\n",
    "For stacking it is ideal that the dataset is relatively large, the author's advice is at least one thousand records. We start our example by loading a relatively large dataset, 20,000 records, this dataset has as characteristic attributes of california houses and as a target value its price, the data is already normalized and we will not make any changes to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>8.3252</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.984127</td>\n",
       "      <td>1.023810</td>\n",
       "      <td>322.0</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>37.88</td>\n",
       "      <td>-122.23</td>\n",
       "      <td>4.526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>8.3014</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.238137</td>\n",
       "      <td>0.971880</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>2.109842</td>\n",
       "      <td>37.86</td>\n",
       "      <td>-122.22</td>\n",
       "      <td>3.585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>7.2574</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.288136</td>\n",
       "      <td>1.073446</td>\n",
       "      <td>496.0</td>\n",
       "      <td>2.802260</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.24</td>\n",
       "      <td>3.521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>5.6431</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.817352</td>\n",
       "      <td>1.073059</td>\n",
       "      <td>558.0</td>\n",
       "      <td>2.547945</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3.8462</td>\n",
       "      <td>52.0</td>\n",
       "      <td>6.281853</td>\n",
       "      <td>1.081081</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.181467</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "0  8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
       "1  8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
       "2  7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
       "3  5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
       "4  3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
       "\n",
       "   Longitude  Price  \n",
       "0    -122.23  4.526  \n",
       "1    -122.22  3.585  \n",
       "2    -122.24  3.521  \n",
       "3    -122.25  3.413  \n",
       "4    -122.25  3.422  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "dataset = fetch_california_housing()\n",
    "df = pd.DataFrame(data=dataset.data, columns=dataset.feature_names)\n",
    "df['Price'] = dataset.target\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we separate into training and testing in a (pseudo) random way to finally evaluate performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>7061</td>\n",
       "      <td>4.1312</td>\n",
       "      <td>35.0</td>\n",
       "      <td>5.882353</td>\n",
       "      <td>0.975490</td>\n",
       "      <td>1218.0</td>\n",
       "      <td>2.985294</td>\n",
       "      <td>33.93</td>\n",
       "      <td>-118.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14689</td>\n",
       "      <td>2.8631</td>\n",
       "      <td>20.0</td>\n",
       "      <td>4.401210</td>\n",
       "      <td>1.076613</td>\n",
       "      <td>999.0</td>\n",
       "      <td>2.014113</td>\n",
       "      <td>32.79</td>\n",
       "      <td>-117.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17323</td>\n",
       "      <td>4.2026</td>\n",
       "      <td>24.0</td>\n",
       "      <td>5.617544</td>\n",
       "      <td>0.989474</td>\n",
       "      <td>731.0</td>\n",
       "      <td>2.564912</td>\n",
       "      <td>34.59</td>\n",
       "      <td>-120.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10056</td>\n",
       "      <td>3.1094</td>\n",
       "      <td>14.0</td>\n",
       "      <td>5.869565</td>\n",
       "      <td>1.094203</td>\n",
       "      <td>302.0</td>\n",
       "      <td>2.188406</td>\n",
       "      <td>39.26</td>\n",
       "      <td>-121.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15750</td>\n",
       "      <td>3.3068</td>\n",
       "      <td>52.0</td>\n",
       "      <td>4.801205</td>\n",
       "      <td>1.066265</td>\n",
       "      <td>1526.0</td>\n",
       "      <td>2.298193</td>\n",
       "      <td>37.77</td>\n",
       "      <td>-122.45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "7061   4.1312      35.0  5.882353   0.975490      1218.0  2.985294     33.93   \n",
       "14689  2.8631      20.0  4.401210   1.076613       999.0  2.014113     32.79   \n",
       "17323  4.2026      24.0  5.617544   0.989474       731.0  2.564912     34.59   \n",
       "10056  3.1094      14.0  5.869565   1.094203       302.0  2.188406     39.26   \n",
       "15750  3.3068      52.0  4.801205   1.066265      1526.0  2.298193     37.77   \n",
       "\n",
       "       Longitude  \n",
       "7061     -118.02  \n",
       "14689    -117.09  \n",
       "17323    -120.14  \n",
       "10056    -121.00  \n",
       "15750    -122.45  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain, xtest, ytrain, ytest =\\\n",
    "    train_test_split(df.drop('Price', axis=1), df.Price, test_size=.3,\n",
    "                     random_state=42)\n",
    "xtrain.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now load cross-validation specifically into [KFold](https://scikit-learn.org/stable/modules/cross_validation.html#k-fold) so that we don't \"lose\" a lot of data, and the templates that will be used , here there is no rule of thumb about the base models, it is up to you, but for the meta-estimator is usually applied boosting trees. Here I arbitrarily chose [kNN](https://scikit-learn.org/stable/modules/neighbors.html#nearest-neighbors-regression) and [ElasticNet](https://scikit-learn.org/stable/modules/linear_model.html#elastic-net), but as a meta-estimator I will use [xgboost](https://xgboost.readthedocs.io/en/latest/tutorials/model.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from xgboost import XGBRFRegressor\n",
    "\n",
    "en = ElasticNet()\n",
    "knn = KNeighborsRegressor()\n",
    "# we will early stop to not overfit\n",
    "gbm = XGBRFRegressor(n_jobs=-1, objective='reg:squarederror')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the creation of the stacked attributes begins, to make sure that there are no biases and we don't have little data to train the meta-estimator we create them by kfolds, being generated the training and test subsets, we train the model in the training set and we predict the value for the test set as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(20, shuffle=True)\n",
    "xtrain['en'] = 0\n",
    "for train_index, test_index in kf.split(xtrain):\n",
    "    en.fit(xtrain.iloc[train_index, :-1], ytrain.iloc[train_index])\n",
    "    xtrain.iloc[test_index,8] = en.predict(xtrain.iloc[test_index, :-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do the same for the other model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>en</th>\n",
       "      <th>knn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>7061</td>\n",
       "      <td>4.1312</td>\n",
       "      <td>35.0</td>\n",
       "      <td>5.882353</td>\n",
       "      <td>0.975490</td>\n",
       "      <td>1218.0</td>\n",
       "      <td>2.985294</td>\n",
       "      <td>33.93</td>\n",
       "      <td>-118.02</td>\n",
       "      <td>2.208931</td>\n",
       "      <td>2.108000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14689</td>\n",
       "      <td>2.8631</td>\n",
       "      <td>20.0</td>\n",
       "      <td>4.401210</td>\n",
       "      <td>1.076613</td>\n",
       "      <td>999.0</td>\n",
       "      <td>2.014113</td>\n",
       "      <td>32.79</td>\n",
       "      <td>-117.09</td>\n",
       "      <td>1.705684</td>\n",
       "      <td>1.809200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17323</td>\n",
       "      <td>4.2026</td>\n",
       "      <td>24.0</td>\n",
       "      <td>5.617544</td>\n",
       "      <td>0.989474</td>\n",
       "      <td>731.0</td>\n",
       "      <td>2.564912</td>\n",
       "      <td>34.59</td>\n",
       "      <td>-120.14</td>\n",
       "      <td>2.098392</td>\n",
       "      <td>1.683200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10056</td>\n",
       "      <td>3.1094</td>\n",
       "      <td>14.0</td>\n",
       "      <td>5.869565</td>\n",
       "      <td>1.094203</td>\n",
       "      <td>302.0</td>\n",
       "      <td>2.188406</td>\n",
       "      <td>39.26</td>\n",
       "      <td>-121.00</td>\n",
       "      <td>1.694140</td>\n",
       "      <td>1.792000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15750</td>\n",
       "      <td>3.3068</td>\n",
       "      <td>52.0</td>\n",
       "      <td>4.801205</td>\n",
       "      <td>1.066265</td>\n",
       "      <td>1526.0</td>\n",
       "      <td>2.298193</td>\n",
       "      <td>37.77</td>\n",
       "      <td>-122.45</td>\n",
       "      <td>2.194403</td>\n",
       "      <td>2.388002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "7061   4.1312      35.0  5.882353   0.975490      1218.0  2.985294     33.93   \n",
       "14689  2.8631      20.0  4.401210   1.076613       999.0  2.014113     32.79   \n",
       "17323  4.2026      24.0  5.617544   0.989474       731.0  2.564912     34.59   \n",
       "10056  3.1094      14.0  5.869565   1.094203       302.0  2.188406     39.26   \n",
       "15750  3.3068      52.0  4.801205   1.066265      1526.0  2.298193     37.77   \n",
       "\n",
       "       Longitude        en       knn  \n",
       "7061     -118.02  2.208931  2.108000  \n",
       "14689    -117.09  1.705684  1.809200  \n",
       "17323    -120.14  2.098392  1.683200  \n",
       "10056    -121.00  1.694140  1.792000  \n",
       "15750    -122.45  2.194403  2.388002  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kf = KFold(20, shuffle=True)\n",
    "xtrain['knn'] = 0\n",
    "\n",
    "for train_index, test_index in kf.split(xtrain):\n",
    "    knn.fit(xtrain.iloc[train_index, :-2], ytrain.iloc[train_index])\n",
    "    xtrain.iloc[test_index,9] = knn.predict(xtrain.iloc[test_index, :-2])\n",
    "\n",
    "xtrain.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have created the features let's evaluate the models in the raw data without the stacked features to check their performances:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7562926012142382\n",
      "1.136942049088978\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "en.fit(xtrain.iloc[:,:-2], ytrain)\n",
    "ypred_en = en.predict(xtest)\n",
    "print(mean_squared_error(ytest, ypred_en))\n",
    "\n",
    "knn.fit(xtrain.iloc[:,:-2], ytrain)\n",
    "ypred_knn = knn.predict(xtest)\n",
    "print(mean_squared_error(ytest, ypred_knn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we create the features with the trained models for the test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>en</th>\n",
       "      <th>knn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20046</td>\n",
       "      <td>1.6812</td>\n",
       "      <td>25.0</td>\n",
       "      <td>4.192201</td>\n",
       "      <td>1.022284</td>\n",
       "      <td>1392.0</td>\n",
       "      <td>3.877437</td>\n",
       "      <td>36.06</td>\n",
       "      <td>-119.01</td>\n",
       "      <td>1.470084</td>\n",
       "      <td>1.6230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3024</td>\n",
       "      <td>2.5313</td>\n",
       "      <td>30.0</td>\n",
       "      <td>5.039384</td>\n",
       "      <td>1.193493</td>\n",
       "      <td>1565.0</td>\n",
       "      <td>2.679795</td>\n",
       "      <td>35.14</td>\n",
       "      <td>-119.46</td>\n",
       "      <td>1.744788</td>\n",
       "      <td>1.0822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15663</td>\n",
       "      <td>3.4801</td>\n",
       "      <td>52.0</td>\n",
       "      <td>3.977155</td>\n",
       "      <td>1.185877</td>\n",
       "      <td>1310.0</td>\n",
       "      <td>1.360332</td>\n",
       "      <td>37.80</td>\n",
       "      <td>-122.44</td>\n",
       "      <td>2.233643</td>\n",
       "      <td>2.8924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20484</td>\n",
       "      <td>5.7376</td>\n",
       "      <td>17.0</td>\n",
       "      <td>6.163636</td>\n",
       "      <td>1.020202</td>\n",
       "      <td>1705.0</td>\n",
       "      <td>3.444444</td>\n",
       "      <td>34.28</td>\n",
       "      <td>-118.72</td>\n",
       "      <td>2.413336</td>\n",
       "      <td>2.2456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9814</td>\n",
       "      <td>3.7250</td>\n",
       "      <td>34.0</td>\n",
       "      <td>5.492991</td>\n",
       "      <td>1.028037</td>\n",
       "      <td>1063.0</td>\n",
       "      <td>2.483645</td>\n",
       "      <td>36.62</td>\n",
       "      <td>-121.93</td>\n",
       "      <td>2.088660</td>\n",
       "      <td>1.6690</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "20046  1.6812      25.0  4.192201   1.022284      1392.0  3.877437     36.06   \n",
       "3024   2.5313      30.0  5.039384   1.193493      1565.0  2.679795     35.14   \n",
       "15663  3.4801      52.0  3.977155   1.185877      1310.0  1.360332     37.80   \n",
       "20484  5.7376      17.0  6.163636   1.020202      1705.0  3.444444     34.28   \n",
       "9814   3.7250      34.0  5.492991   1.028037      1063.0  2.483645     36.62   \n",
       "\n",
       "       Longitude        en     knn  \n",
       "20046    -119.01  1.470084  1.6230  \n",
       "3024     -119.46  1.744788  1.0822  \n",
       "15663    -122.44  2.233643  2.8924  \n",
       "20484    -118.72  2.413336  2.2456  \n",
       "9814     -121.93  2.088660  1.6690  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtest['en'] = ypred_en\n",
    "xtest['knn'] = ypred_knn\n",
    "xtest.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the stacked attributes in hand now we train two models, one without using them, for comparison and another using, let's compare the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without stacked features 0.5828429815199971\n",
      "With stacked features 0.5359477372727965\n"
     ]
    }
   ],
   "source": [
    "#Without stacked features\n",
    "gbm.fit(xtrain.iloc[:,:-2], ytrain.values,\n",
    "        eval_set=[(xtest.iloc[:,:-2],ytest.values)],\n",
    "        early_stopping_rounds=20,\n",
    "        verbose=False)\n",
    "ypred = gbm.predict(xtest.iloc[:,:-2])\n",
    "print(\"Without stacked features\", mean_squared_error(ytest, ypred))\n",
    "# With stacked features\n",
    "gbm.fit(xtrain, ytrain.values,\n",
    "        eval_set=[(xtest,ytest.values)],\n",
    "        early_stopping_rounds=20,\n",
    "        verbose=False)\n",
    "ypred = gbm.predict(xtest)\n",
    "print(\"With stacked features\", mean_squared_error(ytest, ypred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've had a significant improvement using \"stacked\" attributes, concluding our meta estimator learns the best way to combine the features of other estimators, learning their generalization errors and how to correct them, ensuring a much better generalization.\n",
    "\n",
    "#### References\n",
    "\n",
    "[Stacked Generalization](http://machine-learning.martinsewell.com/ensembles/stacking/)\n",
    "\n",
    "[^1]: https://www.sciencedirect.com/science/article/pii/S0893608005800231\n",
    "\n",
    "[^2]: HASTIE, Trevor et al. The elements of statistical learning: data mining, inference and prediction. P. 252, 2005"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
